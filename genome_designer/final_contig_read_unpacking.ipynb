{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wahern/projects/millstone/genome_designer'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from django.core.management import setup_environ\n",
    "import settings\n",
    "setup_environ(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of clipped reads in contig: 56\n"
     ]
    }
   ],
   "source": [
    "# Test extract_contig_reads\n",
    "contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "contig_number = 1\n",
    "genome_finishing_directory_number = 1\n",
    "\n",
    "extract_contig_reads(contig, contig_number, genome_finishing_directory_number, 'clipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pysam\n",
    "from collections import defaultdict\n",
    "from main.models import Contig\n",
    "from main.models import ExperimentSampleToAlignment\n",
    "\n",
    "def extract_contig_reads(contig, contig_number, genome_finishing_directory_number, read_category='all'):\n",
    "    # INPUTS:\n",
    "    # contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "    # contig_number = 1\n",
    "    # genome_finishing_directory_number = 1\n",
    "    \n",
    "    READ_CATEGORY_TO_FILENAME = {\n",
    "        'all': 'bwa_align.SV_indicants_with_pairs.bam',\n",
    "        'without_mates': 'bwa_align.SV_indicants_no_dups.bam',\n",
    "        'clipped': 'bwa_align.clipped.bam',\n",
    "        'split': 'bwa_align.split.bam',\n",
    "        'unmapped': 'bwa_align.unmapped.bam'\n",
    "    }\n",
    "    assert read_category in READ_CATEGORY_TO_FILENAME\n",
    "    \n",
    "    extract_contig_reads_executable = os.path.join(settings.TOOLS_DIR, 'velvet/contrib/extractContigReads/extractContigReads.pl')\n",
    "\n",
    "    sample_alignment = contig.experiment_sample_to_alignment\n",
    "    genome_finish_dir = os.path.join(sample_alignment.get_model_data_dir(), 'genome_finishing')\n",
    "    assembly_dir = os.path.join(genome_finish_dir, str(genome_finishing_directory_number), 'velvet_k21')\n",
    "\n",
    "    read_unpacking_dir = os.path.join(genome_finish_dir, str(genome_finishing_directory_number), 'read_unpacking')\n",
    "    if not os.path.exists(read_unpacking_dir):\n",
    "        os.mkdir(read_unpacking_dir)\n",
    "\n",
    "    contig_number = 1\n",
    "    cmd = [extract_contig_reads_executable, str(contig_number), assembly_dir]\n",
    "    cmd = ' '.join(cmd)\n",
    "\n",
    "    contig_reads_fasta = os.path.join(read_unpacking_dir, 'contig_' + str(contig_number) + '_reads.fa')\n",
    "    if not os.path.exists(contig_reads_fasta):\n",
    "        with open(contig_reads_fasta, 'w') as fh:\n",
    "            subprocess.call(cmd, shell=True, stdout=fh)\n",
    "\n",
    "    p1 = re.compile('>(\\S+)/(\\d)')\n",
    "    contig_reads = defaultdict(list)\n",
    "    with open(contig_reads_fasta) as fh:\n",
    "        for line in fh:\n",
    "            m1 = p1.match(line)\n",
    "            if m1:\n",
    "                read_id = m1.group(1)\n",
    "                read_number = int(m1.group(2))\n",
    "                contig_reads[read_id].append(read_number)\n",
    "\n",
    "    sv_indicant_reads_path = os.path.join(genome_finish_dir, str(genome_finishing_directory_number), READ_CATEGORY_TO_FILENAME[read_category])\n",
    "    sam_file = pysam.AlignmentFile(sv_indicant_reads_path)\n",
    "    sv_indicant_reads_in_contig = []\n",
    "    for read in sam_file:\n",
    "        if read.is_read1:\n",
    "            read_number = 1\n",
    "        elif read.is_read2:\n",
    "            read_number = 2\n",
    "        else:\n",
    "            raise Exception('Read is neither read1 nor read2')\n",
    "\n",
    "        contig_read_numbers = contig_reads.get(read.query_name, [])\n",
    "        if read_number in contig_read_numbers:\n",
    "            sv_indicant_reads_in_contig.append(read)\n",
    "\n",
    "    return sv_indicant_reads_in_contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test extract_contig_reads\n",
    "contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "contig_number = 1\n",
    "genome_finishing_directory_number = 1\n",
    "\n",
    "contig_reads = extract_contig_reads(contig, contig_number, genome_finishing_directory_number, 'clipped')\n",
    "print 'number of extracted reads:', len(contig_reads)\n",
    "\n",
    "extracted_clipped_read_dicts = extract_left_and_right_clipped_read_dicts(contig_reads)\n",
    "left_clipped = extracted_clipped_read_dicts['left_clipped']\n",
    "right_clipped = extract_clipped_read_dicts['right_clipped']\n",
    "\n",
    "ref_insertion_endpoints = find_ref_insertion_endpoints(left_clipped, right_clipped)\n",
    "\n",
    "print 'ref_ins_left_end:', ref_ins_left_end\n",
    "print 'ref_ins_right_end:', ref_ins_right_end\n",
    "# TODO: Handle case of no endpoints found\n",
    "assert ref_ins_left_end is not None and ref_ins_right_end is not None\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-32-c355b5e700f0>, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-c355b5e700f0>\"\u001b[1;36m, line \u001b[1;32m69\u001b[0m\n\u001b[1;33m    def find_contig_insertion_endpoints(left_clipped_same_end, right_clipped_same_end)\u001b[0m\n\u001b[1;37m                                                                                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def extract_left_and_right_clipped_read_dicts(sv_indicant_reads_in_contig):\n",
    "    SOFT_CLIP = 4\n",
    "    HARD_CLIP = 5\n",
    "    CLIP = [SOFT_CLIP, HARD_CLIP]\n",
    "\n",
    "    # Separate left and right clipped reads\n",
    "    left_clipped = defaultdict(list)\n",
    "    right_clipped = defaultdict(list)\n",
    "    for read in sv_indicant_reads_in_contig:\n",
    "        left_clipping = read.cigartuples[0][1] if read.cigartuples[0][0] in CLIP else 0\n",
    "        right_clipping = read.cigartuples[-1][1] if read.cigartuples[-1][0] in CLIP else 0\n",
    "        is_left_clipped = left_clipping > right_clipping\n",
    "        is_right_clipped = right_clipping > left_clipping\n",
    "        if is_left_clipped:\n",
    "            left_clipped[read.reference_start].append(read)\n",
    "        elif is_right_clipped:\n",
    "            right_clipped[read.reference_end].append(read)\n",
    "    \n",
    "    return {\n",
    "        'left_clipped': left_clipped,\n",
    "        'right_clipped': right_clipped\n",
    "    }\n",
    "\n",
    "def find_ref_insertion_endpoints(left_clipped, right_clipped):\n",
    "    \"\"\" left_clipped and right_clipped are dictionaries with lists of\n",
    "    reads as values and the reference start and end of the clipped alignment\n",
    "    as keys respectively\n",
    "    \"\"\"\n",
    "    # Find positions in reference of most left clipping points\n",
    "    left_clipped_list_sorted = sorted(left_clipped.items(), key=lambda x:len(x[1]), reverse=True)\n",
    "    highest_clip_consensus = len(left_clipped_list_sorted[0][1])\n",
    "    second_highest_clip_consensus = len(left_clipped_list_sorted[1][1]) if len(left_clipped_list_sorted) > 1 else 0\n",
    "    if highest_clip_consensus - second_highest_clip_consensus > 2:\n",
    "        ref_ins_right_end = left_clipped_list_sorted[0][0]\n",
    "    else:\n",
    "        ref_ins_right_end = None\n",
    "\n",
    "    # Same for right clipping\n",
    "    right_clipped_list_sorted = sorted(right_clipped.items(), key=lambda x:len(x[1]), reverse=True)\n",
    "    highest_clip_consensus = len(right_clipped_list_sorted[0][1])\n",
    "    second_highest_clip_consensus = len(right_clipped_list_sorted[1][1]) if len(right_clipped_list_sorted) > 1 else 0\n",
    "    if highest_clip_consensus - second_highest_clip_consensus > 2:\n",
    "        ref_ins_left_end = right_clipped_list_sorted[0][0]\n",
    "    else:\n",
    "        ref_ins_left_end = None\n",
    "\n",
    "\n",
    "    return {\n",
    "        'ref_ins_left_end': ref_ins_left_end,\n",
    "        'ref_ins_right_end': ref_ins_right_end\n",
    "    }\n",
    "\n",
    "# Grab query_alignment_sequences for alignment to contig\n",
    "def write_reads_to_fastq(reads, fastq_path):\n",
    "    \"\"\"\n",
    "    T\n",
    "    H\n",
    "    I\n",
    "    S\n",
    "    \n",
    "    IS WHAT I'M WORKING ON\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    right_clipped_query_alignment_seqrecords = []\n",
    "    for read in right_clipped_same_end:\n",
    "        right_clipped_query_alignment_seqrecords.append(SeqRecord(\n",
    "                Seq(read.query_alignment_sequence, IUPAC.ambiguous_dna),\n",
    "                letter_annotations={'phred_quality':read.query_alignment_qualities},\n",
    "                id=read.query_name,\n",
    "                description=''))\n",
    "\n",
    "    right_clipped_query_alignment_fastq = os.path.join(read_unpacking_dir, 'right_clipped_query_alignment_seqs.fq')\n",
    "    with open(right_clipped_query_alignment_fastq, 'w') as fastq_handle:\n",
    "        SeqIO.write(right_clipped_query_alignment_seqrecords, fastq_handle, 'fastq')\n",
    "\n",
    "    \n",
    "def find_contig_insertion_endpoints(left_clipped_same_end, right_clipped_same_end)\n",
    "\"\"\" left_clipped_same_end/right_clipped_same_end are lists of\n",
    "left and right clipped reads all with the same left/right\n",
    "alignment endpoint, corresponding to the reference insertion\n",
    "right/left endpoint\n",
    "\"\"\"\n",
    "# TODO: Handle case of same query_name reads being added to same fastq\n",
    "right_clipped_query_names = [read.query_name for read in right_clipped_same_end]\n",
    "assert len(right_clipped_query_names) == len(set(right_clipped_query_names))\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "right_clipped_query_alignment_seqrecords = []\n",
    "for read in right_clipped_same_end:\n",
    "    right_clipped_query_alignment_seqrecords.append(SeqRecord(\n",
    "            Seq(read.query_alignment_sequence, IUPAC.ambiguous_dna),\n",
    "            letter_annotations={'phred_quality':read.query_alignment_qualities},\n",
    "            id=read.query_name,\n",
    "            description=''))\n",
    "\n",
    "right_clipped_query_alignment_fastq = os.path.join(read_unpacking_dir, 'right_clipped_query_alignment_seqs.fq')\n",
    "with open(right_clipped_query_alignment_fastq, 'w') as fastq_handle:\n",
    "    SeqIO.write(right_clipped_query_alignment_seqrecords, fastq_handle, 'fastq')\n",
    "\n",
    "\n",
    "input_reads_fq = right_clipped_query_alignment_fastq\n",
    "from main.models import Contig\n",
    "from main.models import Dataset\n",
    "contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "contig_fasta = contig.dataset_set.get(type=Dataset.TYPE.REFERENCE_GENOME_FASTA).get_absolute_location()\n",
    "\n",
    "# Align clipped query alignment fastq to contig\n",
    "align_input_args = ' '.join([\n",
    "        '%s/bwa/bwa' % settings.TOOLS_DIR,\n",
    "        'mem',\n",
    "        '-t', '1', # threads\n",
    "        contig_fasta,\n",
    "        input_reads_fq,\n",
    "    ])\n",
    "\n",
    "# To skip saving the SAM file to disk directly, pipe output directly to\n",
    "# make a BAM file.\n",
    "align_input_args += ' | ' + settings.SAMTOOLS_BINARY + ' view -bS -'\n",
    "\n",
    "# Get a BAM filename\n",
    "output_bam = os.path.join(read_unpacking_dir,\n",
    "        'right_clipped_to_contig.bwa_align.bam')\n",
    "\n",
    "# Ensure contig fasta is indexed\n",
    "subprocess.call(' '.join([\n",
    "        '%s/bwa/bwa' % settings.TOOLS_DIR,\n",
    "        'index',\n",
    "        contig_fasta\n",
    "    ]),\n",
    "shell=True, executable=settings.BASH_PATH)\n",
    "\n",
    "# Run alignment\n",
    "import subprocess\n",
    "with open(output_bam, 'w') as fh:\n",
    "    subprocess.check_call(\n",
    "            align_input_args, stdout=fh,\n",
    "            shell=True, executable=settings.BASH_PATH)\n",
    "\n",
    "# # Check if reverse complement contig\n",
    "# right_clipped_qname_to_read = {}\n",
    "# for read in right_clipped[ref_ins_left_end]:\n",
    "#     right_clipped_qname_to_read[read.query_name] = read\n",
    "\n",
    "total_mapped_count = 0\n",
    "reversed_complementarity_count = 0\n",
    "sam_file = pysam.AlignmentFile(output_bam)\n",
    "for read in sam_file:\n",
    "    if not read.is_unmapped:\n",
    "        total_mapped_count += 1\n",
    "        if read.is_reverse:\n",
    "            reversed_complementarity_count += 1\n",
    "\n",
    "REVERSED_COMPLEMENTARITY_FRACTION_CUTOFF = 0.75\n",
    "if reversed_complementarity_count / total_mapped_count > REVERSED_COMPLEMENTARITY_FRACTION_CUTOFF:\n",
    "    print 'Contig is reverse complement'\n",
    "    contig.metadata['is_reverse'] = True\n",
    "\n",
    "# Write reverse complement of contig to file if is reverse\n",
    "if contig.metadata.get('is_reverse', False):\n",
    "    rc_contig_fasta = os.path.splitext(contig_fasta)[0] + '.reverse_complement.fa'\n",
    "    print 'reverse complement contig fasta:', rc_contig_fasta\n",
    "    contig_seqrecord = SeqIO.parse(contig_fasta, 'fasta').next()\n",
    "    contig_seqrecord.seq = contig_seqrecord.seq.reverse_complement()\n",
    "    SeqIO.write(contig_seqrecord, rc_contig_fasta, 'fasta')\n",
    "    \n",
    "    # Align clipped query alignment fastq to contig\n",
    "    align_input_args = ' '.join([\n",
    "            '%s/bwa/bwa' % settings.TOOLS_DIR,\n",
    "            'mem',\n",
    "            '-t', '1', # threads\n",
    "            rc_contig_fasta,\n",
    "            input_reads_fq,\n",
    "        ])\n",
    "\n",
    "    # To skip saving the SAM file to disk directly, pipe output directly to\n",
    "    # make a BAM file.\n",
    "    align_input_args += ' | ' + settings.SAMTOOLS_BINARY + ' view -bS -'\n",
    "\n",
    "    # Get a BAM filename\n",
    "    output_bam = os.path.join(read_unpacking_dir,\n",
    "            'right_clipped_to_contig.bwa_align.bam')\n",
    "\n",
    "    # Ensure contig fasta is indexed\n",
    "    subprocess.call(' '.join([\n",
    "            '%s/bwa/bwa' % settings.TOOLS_DIR,\n",
    "            'index',\n",
    "            rc_contig_fasta\n",
    "        ]),\n",
    "    shell=True, executable=settings.BASH_PATH)\n",
    "\n",
    "    # Run alignment\n",
    "    import subprocess\n",
    "    with open(output_bam, 'w') as fh:\n",
    "        subprocess.check_call(\n",
    "                align_input_args, stdout=fh,\n",
    "                shell=True, executable=settings.BASH_PATH)\n",
    "\n",
    "\n",
    "alignment_ref_end_positions = defaultdict(list)\n",
    "sam_file = pysam.AlignmentFile(output_bam)\n",
    "for read in sam_file:\n",
    "    # Change to reference_start for left_clipped\n",
    "    alignment_ref_end_positions[read.reference_end].append(read)\n",
    "#     print 'read.reference_start:', read.reference_start\n",
    "#     print 'read.reference_end:', read.reference_end\n",
    "\n",
    "alignment_ref_end_positions_sorted = sorted(alignment_ref_end_positions.items(), key=lambda x:len(x[1]), reverse=True)\n",
    "highest_end_consensus = len(alignment_ref_end_positions_sorted[0][1])\n",
    "second_highest_end_consensus = len(alignment_ref_end_positions_sorted[1][1]) if len(alignment_ref_end_positions_sorted) > 1 else 0\n",
    "if highest_end_consensus - second_highest_end_consensus > 2:\n",
    "    contig_ins_left_end = alignment_ref_end_positions_sorted[0][0]\n",
    "else:\n",
    "    contig_ins_left_end = None\n",
    "\n",
    "print 'contig_ins_left_end:', contig_ins_left_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
