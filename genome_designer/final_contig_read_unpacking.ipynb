{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wahern/projects/millstone/genome_designer'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from django.core.management import setup_environ\n",
    "import settings\n",
    "# from django.conf import settings\n",
    "setup_environ(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from main.models import ReferenceGenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test extract_contig_reads\n",
    "contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "contig_number = 1\n",
    "genome_finishing_directory_number = 1\n",
    "\n",
    "extract_contig_reads(contig, contig_number, genome_finishing_directory_number, 'clipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pysam\n",
    "from collections import defaultdict\n",
    "from main.models import Contig\n",
    "from main.models import ExperimentSampleToAlignment\n",
    "\n",
    "def extract_contig_reads(contig, contig_number, genome_finishing_directory_number,\n",
    "                         read_unpacking_dir, read_category='all'):\n",
    "    # INPUTS:\n",
    "    # contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "    # contig_number = 1\n",
    "    # genome_finishing_directory_number = 1\n",
    "    \n",
    "    READ_CATEGORY_TO_FILENAME = {\n",
    "        'all': 'bwa_align.SV_indicants_with_pairs.bam',\n",
    "        'without_mates': 'bwa_align.SV_indicants_no_dups.bam',\n",
    "        'clipped': 'bwa_align.clipped.bam',\n",
    "        'split': 'bwa_align.split.bam',\n",
    "        'unmapped': 'bwa_align.unmapped.bam'\n",
    "    }\n",
    "    assert read_category in READ_CATEGORY_TO_FILENAME\n",
    "    \n",
    "    extract_contig_reads_executable = os.path.join(settings.TOOLS_DIR, 'velvet/contrib/extractContigReads/extractContigReads.pl')\n",
    "\n",
    "    sample_alignment = contig.experiment_sample_to_alignment\n",
    "    genome_finish_dir = os.path.join(sample_alignment.get_model_data_dir(), 'genome_finishing')\n",
    "    assembly_dir = os.path.join(genome_finish_dir, str(genome_finishing_directory_number), 'velvet_k21')\n",
    "\n",
    "    contig_number = 1\n",
    "    cmd = [extract_contig_reads_executable, str(contig_number), assembly_dir]\n",
    "    cmd = ' '.join(cmd)\n",
    "\n",
    "    contig_reads_fasta = os.path.join(read_unpacking_dir, 'contig_' + str(contig_number) + '_reads.fa')\n",
    "    if not os.path.exists(contig_reads_fasta):\n",
    "        with open(contig_reads_fasta, 'w') as fh:\n",
    "            subprocess.call(cmd, shell=True, stdout=fh)\n",
    "\n",
    "    p1 = re.compile('>(\\S+)/(\\d)')\n",
    "    contig_reads = defaultdict(list)\n",
    "    with open(contig_reads_fasta) as fh:\n",
    "        for line in fh:\n",
    "            m1 = p1.match(line)\n",
    "            if m1:\n",
    "                read_id = m1.group(1)\n",
    "                read_number = int(m1.group(2))\n",
    "                contig_reads[read_id].append(read_number)\n",
    "\n",
    "    sv_indicant_reads_path = os.path.join(genome_finish_dir, str(genome_finishing_directory_number), READ_CATEGORY_TO_FILENAME[read_category])\n",
    "    sam_file = pysam.AlignmentFile(sv_indicant_reads_path)\n",
    "    sv_indicant_reads_in_contig = []\n",
    "    for read in sam_file:\n",
    "        if read.is_read1:\n",
    "            read_number = 1\n",
    "        elif read.is_read2:\n",
    "            read_number = 2\n",
    "        else:\n",
    "            raise Exception('Read is neither read1 nor read2')\n",
    "\n",
    "        contig_read_numbers = contig_reads.get(read.query_name, [])\n",
    "        if read_number in contig_read_numbers:\n",
    "            sv_indicant_reads_in_contig.append(read)\n",
    "\n",
    "    return sv_indicant_reads_in_contig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.Alphabet import IUPAC\n",
    "from Bio import SeqIO\n",
    "from main.models import Dataset\n",
    "import subprocess\n",
    "\n",
    "\n",
    "ENDPOINT_MODE_DIFFERENCE_CUTOFF = 2\n",
    "\n",
    "def extract_left_and_right_clipped_read_dicts(sv_indicant_reads_in_contig):\n",
    "    SOFT_CLIP = 4\n",
    "    HARD_CLIP = 5\n",
    "    CLIP = [SOFT_CLIP, HARD_CLIP]\n",
    "\n",
    "    # Separate left and right clipped reads\n",
    "    left_clipped = defaultdict(list)\n",
    "    right_clipped = defaultdict(list)\n",
    "    for read in sv_indicant_reads_in_contig:\n",
    "        left_clipping = read.cigartuples[0][1] if read.cigartuples[0][0] in CLIP else 0\n",
    "        right_clipping = read.cigartuples[-1][1] if read.cigartuples[-1][0] in CLIP else 0\n",
    "        is_left_clipped = left_clipping > right_clipping\n",
    "        is_right_clipped = right_clipping > left_clipping\n",
    "        if is_left_clipped:\n",
    "            left_clipped[read.reference_start].append(read)\n",
    "        elif is_right_clipped:\n",
    "            right_clipped[read.reference_end].append(read)\n",
    "    \n",
    "    return {\n",
    "        'left_clipped': left_clipped,\n",
    "        'right_clipped': right_clipped\n",
    "    }\n",
    "\n",
    "def find_ref_insertion_endpoints(left_clipped, right_clipped):\n",
    "    \"\"\" left_clipped and right_clipped are dictionaries with lists of\n",
    "    reads as values and the reference start and end of the clipped alignment\n",
    "    as keys respectively\n",
    "    \"\"\"\n",
    "    # Find positions in reference of most left clipping points\n",
    "    left_clipped_list_sorted = sorted(left_clipped.items(), key=lambda x:len(x[1]), reverse=True)\n",
    "    highest_clip_consensus = len(left_clipped_list_sorted[0][1])\n",
    "    second_highest_clip_consensus = len(left_clipped_list_sorted[1][1]) if len(left_clipped_list_sorted) > 1 else 0\n",
    "    if highest_clip_consensus - second_highest_clip_consensus > 2:\n",
    "        ref_ins_right_end = left_clipped_list_sorted[0][0]\n",
    "    else:\n",
    "        ref_ins_right_end = None\n",
    "\n",
    "    # Same for right clipping\n",
    "    right_clipped_list_sorted = sorted(right_clipped.items(), key=lambda x:len(x[1]), reverse=True)\n",
    "    highest_clip_consensus = len(right_clipped_list_sorted[0][1])\n",
    "    second_highest_clip_consensus = len(right_clipped_list_sorted[1][1]) if len(right_clipped_list_sorted) > 1 else 0\n",
    "    if highest_clip_consensus - second_highest_clip_consensus > 2:\n",
    "        ref_ins_left_end = right_clipped_list_sorted[0][0]\n",
    "    else:\n",
    "        ref_ins_left_end = None\n",
    "\n",
    "    return {\n",
    "        'left': ref_ins_left_end,\n",
    "        'right': ref_ins_right_end\n",
    "    }\n",
    "\n",
    "# Grab query_alignment_sequences for alignment to contig\n",
    "def write_read_query_alignments_to_fastq(reads, fastq_path):\n",
    "    \"\"\"Writes the aligned portion of each read into a fastq\n",
    "    \"\"\"\n",
    "\n",
    "    query_alignment_seqrecords = []\n",
    "    for read in reads:\n",
    "        query_alignment_seqrecords.append(SeqRecord(\n",
    "                Seq(read.query_alignment_sequence, IUPAC.ambiguous_dna),\n",
    "                letter_annotations={'phred_quality':read.query_alignment_qualities},\n",
    "                id=read.query_name,\n",
    "                description=''))\n",
    "\n",
    "    with open(fastq_path, 'w') as fastq_handle:\n",
    "        SeqIO.write(query_alignment_seqrecords, fastq_handle, 'fastq')\n",
    "        \n",
    "def simple_align_with_bwa_mem(reads_fq, reference_fasta, output_bam_path):\n",
    "    \n",
    "    # Ensure reference fasta is indexed\n",
    "    subprocess.call(' '.join([\n",
    "            '%s/bwa/bwa' % settings.TOOLS_DIR,\n",
    "            'index',\n",
    "            reference_fasta\n",
    "            ]),\n",
    "            shell=True, executable=settings.BASH_PATH)\n",
    "\n",
    "    # Align clipped query alignment fastq to contig\n",
    "    align_input_args = ' '.join([\n",
    "            '%s/bwa/bwa' % settings.TOOLS_DIR,\n",
    "            'mem',\n",
    "            '-t', '1', # threads\n",
    "            reference_fasta,\n",
    "            reads_fq,])\n",
    "\n",
    "    # To skip saving the SAM file to disk directly, pipe output directly to\n",
    "    # make a BAM file.\n",
    "    align_input_args += ' | ' + settings.SAMTOOLS_BINARY + ' view -bS -'\n",
    "\n",
    "    # Run alignment\n",
    "    with open(output_bam_path, 'w') as fh:\n",
    "        subprocess.check_call(\n",
    "                align_input_args, stdout=fh,\n",
    "                shell=True, executable=settings.BASH_PATH)\n",
    "        \n",
    "\n",
    "def get_reads_with_mode_attribute(clipped_alignment_bam, get_attr_function,\n",
    "                                  mode_difference_cutoff=ENDPOINT_MODE_DIFFERENCE_CUTOFF):\n",
    "    alignment_ref_clip_positions = defaultdict(list)\n",
    "    sam_file = pysam.AlignmentFile(clipped_alignment_bam)\n",
    "    for read in sam_file:\n",
    "        # Change to reference_start for left_clipped\n",
    "        alignment_ref_clip_positions[get_attr_function(read)].append(read)\n",
    "        # alignment_ref_end_positions[read.reference_end].append(read)\n",
    "\n",
    "    alignment_ref_clip_positions_sorted = sorted(alignment_ref_clip_positions.items(), key=lambda x:len(x[1]), reverse=True)\n",
    "    highest_consensus = len(alignment_ref_clip_positions_sorted[0][1])\n",
    "    second_highest_consensus = len(alignment_ref_clip_positions_sorted[1][1]) if len(alignment_ref_clip_positions_sorted) > 1 else 0\n",
    "    if highest_consensus - second_highest_consensus > mode_difference_cutoff:\n",
    "        endpoint = alignment_ref_clip_positions_sorted[0][0]\n",
    "    else:\n",
    "        endpoint = None\n",
    "\n",
    "    return endpoint\n",
    "\n",
    "\n",
    "def find_contig_insertion_endpoints(contig, read_unpacking_dir, left_clipped_same_end, right_clipped_same_end):\n",
    "    \"\"\" left_clipped_same_end/right_clipped_same_end are lists of\n",
    "    left and right clipped reads all with the same left/right\n",
    "    alignment endpoint, corresponding to the reference insertion\n",
    "    right/left endpoint\n",
    "    \"\"\"\n",
    "    # TODO: Handle case of same query_name reads being added to same fastq\n",
    "    right_clipped_query_names = [read.query_name for read in right_clipped_same_end]\n",
    "    assert len(right_clipped_query_names) == len(set(right_clipped_query_names))\n",
    "\n",
    "    # Write left and right clipped query alignment sequences to fastq\n",
    "    right_clipped_query_alignment_fq = os.path.join(\n",
    "            read_unpacking_dir, 'right_clipped_query_alignment_seqs.fq')\n",
    "    write_read_query_alignments_to_fastq(right_clipped_same_end,\n",
    "                                         right_clipped_query_alignment_fq)\n",
    "    left_clipped_query_alignment_fq = os.path.join(\n",
    "            read_unpacking_dir, 'left_clipped_query_alignment_seqs.fq')\n",
    "    write_read_query_alignments_to_fastq(left_clipped_same_end,\n",
    "                                         left_clipped_query_alignment_fq)\n",
    "\n",
    "    # Get BAM filenames for right_clipped and left_clipped alignments\n",
    "    right_clipped_to_contig_bam = os.path.join(read_unpacking_dir,\n",
    "            'right_clipped_to_contig.bwa_align.bam')\n",
    "    left_clipped_to_contig_bam = os.path.join(read_unpacking_dir,\n",
    "            'left_clipped_to_contig.bwa_align.bam')\n",
    "    \n",
    "    \n",
    "    # Only perform alignment of right_clipped to contig\n",
    "    contig_fasta = contig.dataset_set.get(\n",
    "            type=Dataset.TYPE.REFERENCE_GENOME_FASTA).get_absolute_location()\n",
    "    simple_align_with_bwa_mem(\n",
    "            right_clipped_query_alignment_fq, contig_fasta,\n",
    "            right_clipped_to_contig_bam)\n",
    "\n",
    "    # Check if contig is reverse complement\n",
    "    total_mapped_count = 0\n",
    "    reversed_complementarity_count = 0\n",
    "    sam_file = pysam.AlignmentFile(right_clipped_to_contig_bam)\n",
    "    for read in sam_file:\n",
    "        if not read.is_unmapped:\n",
    "            total_mapped_count += 1\n",
    "            if read.is_reverse:\n",
    "                reversed_complementarity_count += 1\n",
    "\n",
    "    REVERSED_COMPLEMENTARITY_FRACTION_CUTOFF = 0.75\n",
    "    if reversed_complementarity_count / total_mapped_count > REVERSED_COMPLEMENTARITY_FRACTION_CUTOFF:\n",
    "        print 'Contig is reverse complement'\n",
    "        contig.metadata['is_reverse'] = True\n",
    "\n",
    "    # Write reverse complement of contig to file if is reverse\n",
    "    if contig.metadata.get('is_reverse', False):\n",
    "        rc_contig_fasta = os.path.splitext(contig_fasta)[0] + '.reverse_complement.fa'\n",
    "        print 'reverse complement contig fasta:', rc_contig_fasta\n",
    "        contig_seqrecord = SeqIO.parse(contig_fasta, 'fasta').next()\n",
    "        contig_seqrecord.seq = contig_seqrecord.seq.reverse_complement()\n",
    "        SeqIO.write(contig_seqrecord, rc_contig_fasta, 'fasta')\n",
    "    \n",
    "        # Redo right_clipped alignment to reverse complement of contig\n",
    "        simple_align_with_bwa_mem(\n",
    "                right_clipped_query_alignment_fq, rc_contig_fasta,\n",
    "                right_clipped_to_contig_bam)\n",
    "        \n",
    "        # Perform left_clipped alignmnet to reverse complement of contig\n",
    "        simple_align_with_bwa_mem(\n",
    "                left_clipped_query_alignment_fq, rc_contig_fasta,\n",
    "                left_clipped_to_contig_bam)\n",
    "    else:\n",
    "        # Perform left_clipped alignmnet to contig\n",
    "        simple_align_with_bwa_mem(\n",
    "                left_clipped_query_alignment_fq, contig_fasta,\n",
    "                left_clipped_to_contig_bam)\n",
    "    \n",
    "    # Find contig endpoints\n",
    "    contig_ins_left_end = get_reads_with_mode_attribute(right_clipped_to_contig_bam, lambda r:r.reference_end)\n",
    "    contig_ins_right_end = get_reads_with_mode_attribute(left_clipped_to_contig_bam, lambda r:r.reference_start)\n",
    "\n",
    "    print 'contig_ins_left_end:', contig_ins_left_end\n",
    "    print 'contig_ins_right_end:', contig_ins_right_end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contig': {'left': 491, 'right': 1491},\n",
       " 'referenece': {'left': 20000, 'right': 20000}}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main.models import Contig\n",
    "from genome_finish.insertion_placement_read_trkg import get_insertion_placement_positions\n",
    "\n",
    "contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "contig_number = 1\n",
    "genome_finishing_directory_number = 1\n",
    "get_insertion_placement_positions(contig, contig_number, genome_finishing_directory_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'genome_finish.insertion_placement_read_trkg' from 'genome_finish/insertion_placement_read_trkg.py'>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(genome_finish.insertion_placement_read_trkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "java -jar /home/wahern/projects/millstone/genome_designer/tools/snpEff/snpEff.jar build -genbank -v 60df3b51 -c /home/wahern/projects/millstone/genome_designer/temp_data/projects/ecbcef23/ref_genomes/60df3b51/snpeff/snpeff.config -q -noLog\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ReferenceGenome: test_make_rg_1>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main.models import Contig\n",
    "from genome_finish.insertion_placement_read_trkg import place_contig\n",
    "contig = Contig.objects.get(label='ins_1kb_ins_1kb_sample_NODE_1_length_1966_cov_23.051373')\n",
    "\n",
    "# contig.experiment_sample_to_alignment.get_model_data_dir()\n",
    "# contig.metadata['assembly_dir'] = '/home/wahern/projects/millstone/genome_designer/conf/../temp_data/projects/ecbcef23/alignment_groups/85ad25c6/sample_alignments/37886b79/genome_finishing/1/velvet_k21' \n",
    "# contig.metadata['node_number'] = 1\n",
    "# contig.save()\n",
    "\n",
    "place_contig(contig, 'test_make_rg_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'coverage': 23.051373,\n",
       " 'is_reverse': True,\n",
       " u'timestamp': u'2015-07-15 11:46:25.414577'}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contig.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yay you're a winner\n"
     ]
    }
   ],
   "source": [
    "# Verify expected transformation\n",
    "import os\n",
    "from django.conf import settings\n",
    "from main.models import Dataset\n",
    "from main.models import ReferenceGenome\n",
    "from main.model_utils import get_dataset_with_type\n",
    "from Bio import SeqIO\n",
    "\n",
    "INS_1KB_TRANSFORMED_FASTA_PATH = os.path.join(\n",
    "        settings.PWD,\n",
    "        'test_data/genome_finish_test/ins_1kb_transformed.fa')\n",
    "\n",
    "placed_contig_ref_genome = ReferenceGenome.objects.get(\n",
    "        label='new_ref_test_4')\n",
    "\n",
    "placed_contig_fasta = get_dataset_with_type(\n",
    "        placed_contig_ref_genome,\n",
    "        Dataset.TYPE.REFERENCE_GENOME_FASTA).get_absolute_location()\n",
    "\n",
    "with open(placed_contig_fasta, 'r') as fh:\n",
    "    placed_contig_seqrecord = SeqIO.parse(fh, 'fasta').next()\n",
    "\n",
    "with open(INS_1KB_TRANSFORMED_FASTA_PATH, 'r') as fh:\n",
    "    transformed_seqrecord = SeqIO.parse(fh, 'fasta').next()\n",
    "\n",
    "assert str(placed_contig_seqrecord.seq) == str(transformed_seqrecord.seq)\n",
    "\n",
    "print 'Yay you\\'re a winner'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCGTTGCGTTTTCAACTTTCGCCACCAGTTCAGCATACGCTAAATTACGGTTGCCATGATCGCCAGAATAATCGGTAAAATCGTAGCCCGCGGTAATGGATCCTCATAACCCTGCTTTCAAACTTGCTTCGATAAATTGATCCAGGCTGCCGTCCAGCACGGCCTGCGTGTTGCGGGTTTCTACCCCGGTGCGCAGATCTTTAATGCGGGAGTCATCAAGGACATAAGAACGAATCTGGCTGCCCCAGCCGATGTCGGATTTGTTATCTTCCATCGCCTGTTTCTCGGCATTTTTCTTCTGCATCTCCAGTTCATAAAGCTTCGCTTTCATCTGCTTCATGGCCTGATCTTTGTTCTTGTGCTGGGAACGGTCGTTCTGGCACTGGGTCACGATCCCGGTCGGGATGTGGGTAATACGCACCGCAGATTCGGTACGGTTAACGTGCTGACCGCCCGCGCCGGACGTGCGATAAACGTCAATGCGCAGATCCGCCGGGTTGATTTCGATATCAATATCATCATCAACTTCCGGATAAACAAACGCGGAGCTGAACGACGTGTGGCGACGACCGCCGGAGTCAAACGGGCTTTTACGCACCAGGCGGTGAACGCCGGTTTCTGTACGCAGCCAGCCGTAAGCGTAATCGCCGGAGATTTTGATCGTCACGGATTTAATACCCGCCACTTCACCTTCCGACTCTTCGATGATTTCAGTTTTGAAACCACGCGATTCTGCCCAGCGCAGATACATACGCTCAAGCATGCTCGCCCAGTCCTGTGCTTCCGTACCGCCAGACCCCGCCTGAATATCGAGGTAGCAGTCGGCGCTGTCATATTCGCCAGAGAACATACGGCGGAACTCAAGCTGCGCCAGTTTTTCTTCCAGGGCGTCGAGTTCAGCAACGGCTTCGTTAAAGGTTTCTTCGTCGTCAGCTTCTACAGCCAGTTCCAGCAGACCAGAAACATCTTCCAGCCCCTGTTTCATTTGGTCGAGGGTGTCGACAACGGCTTCGAGGGAGGAACGCTCTTTACCCAGCGCCTGTGCGCGTTCGGGTTCGTTCCAGACATCCGGCTGTTCCAGCTCGGCGTTTACTTCTTCCAGTTAACCCGGCATAAGCGGGCAATGCGCTAAAAATGGCCGCCGCTAATAACGTCCGTTTTATCATTTTAATCTCCTGTACGGATAAGTTCTTGTCGGAG'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(transformed_seqrecord.seq[19900:21100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GCGTTGCGTTTTCAACTTTCGCCACCAGTTCAGCATACGCTAAATTACGGTTGCCATGATCGCCAGAATAATCGGTAAAATCGTAGCCCGCGGTAATGGTCCTCATAACCCTGCTTTCAAACTTGCTTCGATAAATTGATCCAGGCTGCCGTCCAGCACGGCCTGCGTGTTGCGGGTTTCTACCCCGGTGCGCAGATCTTTAATGCGGGAGTCATCAAGGACATAAGAACGAATCTGGCTGCCCCAGCCGATGTCGGATTTGTTATCTTCCATCGCCTGTTTCTCGGCATTTTTCTTCTGCATCTCCAGTTCATAAAGCTTCGCTTTCATCTGCTTCATGGCCTGATCTTTGTTCTTGTGCTGGGAACGGTCGTTCTGGCACTGGGTCACGATCCCGGTCGGGATGTGGGTAATACGCACCGCAGATTCGGTACGGTTAACGTGCTGACCGCCCGCGCCGGACGTGCGATAAACGTCAATGCGCAGATCCGCCGGGTTGATTTCGATATCAATATCATCATCAACTTCCGGATAAACAAACGCGGAGCTGAACGACGTGTGGCGACGACCGCCGGAGTCAAACGGGCTTTTACGCACCAGGCGGTGAACGCCGGTTTCTGTACGCAGCCAGCCGTAAGCGTAATCGCCGGAGATTTTGATCGTCACGGATTTAATACCCGCCACTTCACCTTCCGACTCTTCGATGATTTCAGTTTTGAAACCACGCGATTCTGCCCAGCGCAGATACATACGCTCAAGCATGCTCGCCCAGTCCTGTGCTTCCGTACCGCCAGACCCCGCCTGAATATCGAGGTAGCAGTCGGCGCTGTCATATTCGCCAGAGAACATACGGCGGAACTCAAGCTGCGCCAGTTTTTCTTCCAGGGCGTCGAGTTCAGCAACGGCTTCGTTAAAGGTTTCTTCGTCGTCAGCTTCTACAGCCAGTTCCAGCAGACCAGAAACATCTTCCAGCCCCTGTTTCATTTGGTCGAGGGTGTCGACAACGGCTTCGAGGGAGGAACGCTCTTTACCCAGCGCCTGTGCGCGTTCGGGTTCGTTCCAGACATCCGGCTGTTCCAGCTCGGCGTTTACTTCTTCCAAGTTAACCCGGCATAAGCGGGCAATGCGCTAAAAATGGCCGCCGCTAATAACGTCCGTTTTATCATTTTAATCTCCTGTACGGATAAGTTCTTGTCGGAG'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(placed_contig_seqrecord.seq[19900:21100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
